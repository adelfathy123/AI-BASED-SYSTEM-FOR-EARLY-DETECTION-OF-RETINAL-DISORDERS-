{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip uninstall -y jax jaxlib\n","!pip install --upgrade --quiet jax jaxlib\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"triukU8eg09A","outputId":"9ad64523-93af-4c7d-dd05-69223f4fa840"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: jax 0.6.2\n","Uninstalling jax-0.6.2:\n","  Successfully uninstalled jax-0.6.2\n","Found existing installation: jaxlib 0.6.2\n","Uninstalling jaxlib-0.6.2:\n","  Successfully uninstalled jaxlib-0.6.2\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from tensorflow.keras.models import load_model, Model\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.inception_v3 import preprocess_input\n","from sklearn.svm import SVC\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from tqdm import tqdm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sx2RyEVGh9rQ","outputId":"8ecd2e84-8377-4b60-92e4-c033cb10f7b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.5.1 is installed, but it is not compatible with the installed jaxlib version 0.6.2, so it will not be used.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# --------- Settings ---------\n","img_size = 299\n","base_path = \"/content/drive/MyDrive/graduation project/trial_split\"\n","splits = [\"train\", \"val\", \"test\"]\n","classes = ['AMD', 'DME', 'ERM', 'NO']\n","model_path = \"/content/drive/MyDrive/graduation project/models/OCT_InceptionV3.h5\"\n","output_path = \"/content/drive/MyDrive/graduation project/features\"\n","\n","# --------- Load Trained Model and Create Feature Extractor ---------\n","full_model = load_model(model_path)\n","feature_extractor = Model(inputs=full_model.input, outputs=full_model.layers[-3].output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLdg2BvTobGS","outputId":"1eff0400-28f7-4cf4-bb9b-42edb5803018"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"]}]},{"cell_type":"code","source":["# --------- Feature Extraction Function ---------\n","def extract_features(split):\n","    features = []\n","    labels = []\n","    for class_index, class_name in enumerate(classes):\n","        class_path = os.path.join(base_path, split, class_name)\n","        image_files = os.listdir(class_path)\n","        for img_file in tqdm(image_files, desc=f\"{split}/{class_name}\"):\n","            img_path = os.path.join(class_path, img_file)\n","            try:\n","                img = image.load_img(img_path, target_size=(img_size, img_size))\n","                img_array = image.img_to_array(img)\n","                img_array = np.expand_dims(img_array, axis=0)\n","                img_array = preprocess_input(img_array)\n","                feature = feature_extractor.predict(img_array, verbose=0)\n","                features.append(feature.flatten())\n","                labels.append(class_index)\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Error with image {img_path}: {e}\")\n","    return np.array(features), np.array(labels)\n"],"metadata":{"id":"c2npnLHXpJwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --------- Extract and Save Features ---------\n","os.makedirs(output_path, exist_ok=True)\n","for split in splits:\n","    X, y = extract_features(split)\n","    np.save(os.path.join(output_path, f\"X_{split}.npy\"), X)\n","    np.save(os.path.join(output_path, f\"y_{split}.npy\"), y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvr0yin8pNY6","outputId":"6c178097-dbeb-42f3-f2ea-37732984667f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["train/AMD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 861/861 [06:15<00:00,  2.29it/s]\n","train/DME: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 823/823 [05:48<00:00,  2.36it/s]\n","train/ERM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 868/868 [06:11<00:00,  2.34it/s]\n","train/NO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 929/929 [06:30<00:00,  2.38it/s]\n","val/AMD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184/184 [01:21<00:00,  2.27it/s]\n","val/DME: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [01:18<00:00,  2.25it/s]\n","val/ERM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:27<00:00,  2.12it/s]\n","val/NO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [01:25<00:00,  2.33it/s]\n","test/AMD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:26<00:00,  2.15it/s]\n","test/DME: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [01:15<00:00,  2.35it/s]\n","test/ERM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:25<00:00,  2.18it/s]\n","test/NO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [01:28<00:00,  2.25it/s]\n"]}]},{"cell_type":"code","source":["# --------- Load Saved Features ---------\n","X_train = np.load(os.path.join(output_path, \"X_train.npy\"))\n","y_train = np.load(os.path.join(output_path, \"y_train.npy\"))\n","X_val = np.load(os.path.join(output_path, \"X_val.npy\"))\n","y_val = np.load(os.path.join(output_path, \"y_val.npy\"))\n","X_test = np.load(os.path.join(output_path, \"X_test.npy\"))\n","y_test = np.load(os.path.join(output_path, \"y_test.npy\"))\n"],"metadata":{"id":"LybBcerUpROQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --------- Train SVM Classifier ---------\n","print(\"\\nüîß Training SVM...\")\n","svm = SVC(kernel='linear', probability=True)\n","svm.fit(X_train, y_train)\n","pred_svm = svm.predict(X_test)\n","print(\"\\nüìä SVM Results:\")\n","print(classification_report(y_test, pred_svm, target_names=classes))\n","print(\"Accuracy:\", accuracy_score(y_test, pred_svm))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOgJ96DMpUah","outputId":"1ad0e919-fb27-41b9-9d58-b969c288cfa4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîß Training SVM...\n","\n","üìä SVM Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.94      0.96      0.95       186\n","         DME       0.95      0.95      0.95       177\n","         ERM       0.95      0.94      0.94       186\n","          NO       0.96      0.96      0.96       200\n","\n","    accuracy                           0.95       749\n","   macro avg       0.95      0.95      0.95       749\n","weighted avg       0.95      0.95      0.95       749\n","\n","Accuracy: 0.951935914552737\n"]}]},{"cell_type":"code","source":["\n","# --------- Train XGBoost (GradientBoosting) ---------\n","print(\"\\nüîß Training XGBoost...\")\n","xgb = GradientBoostingClassifier()\n","xgb.fit(X_train, y_train)\n","pred_xgb = xgb.predict(X_test)\n","print(\"\\nüìä XGBoost Results:\")\n","print(classification_report(y_test, pred_xgb, target_names=classes))\n","print(\"Accuracy:\", accuracy_score(y_test, pred_xgb))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RfHbsFQFpaHj","outputId":"40c82752-0b4b-4e3f-ddb2-a21201c87c1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîß Training XGBoost...\n","\n","üìä XGBoost Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.95      0.95      0.95       186\n","         DME       0.93      0.95      0.94       177\n","         ERM       0.95      0.93      0.94       186\n","          NO       0.96      0.96      0.96       200\n","\n","    accuracy                           0.95       749\n","   macro avg       0.95      0.95      0.95       749\n","weighted avg       0.95      0.95      0.95       749\n","\n","Accuracy: 0.9492656875834445\n"]}]},{"cell_type":"code","source":["# üîÅ Ensemble (SVM + XGBoost) Classifier on Extracted Features\n","\n","import numpy as np\n","from sklearn.svm import SVC\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","\n","# --------- Load Features ---------\n","X_train = np.load(\"/content/drive/MyDrive/graduation project/features/X_train.npy\")\n","y_train = np.load(\"/content/drive/MyDrive/graduation project/features/y_train.npy\")\n","X_test = np.load(\"/content/drive/MyDrive/graduation project/features/X_test.npy\")\n","y_test = np.load(\"/content/drive/MyDrive/graduation project/features/y_test.npy\")\n","\n","# --------- Normalize Features ---------\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# --------- Define Classifiers ---------\n","svm_clf = SVC(kernel='rbf', probability=True, C=10, gamma=0.01, random_state=42)\n","xgb_clf = XGBClassifier(n_estimators=300, max_depth=5, learning_rate=0.05, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n","\n","# --------- Voting Classifier ---------\n","ensemble_model = VotingClassifier(estimators=[\n","    ('svm', svm_clf),\n","    ('xgb', xgb_clf)\n","], voting='soft')\n","\n","# --------- Train Ensemble ---------\n","print(\"\\nüîß Training Ensemble (SVM + XGBoost)...\")\n","ensemble_model.fit(X_train, y_train)\n","\n","# --------- Evaluate ---------\n","y_pred = ensemble_model.predict(X_test)\n","print(\"\\nüìä Ensemble Results:\")\n","print(classification_report(y_test, y_pred, target_names=['AMD', 'DME', 'ERM', 'NO']))\n","print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFGb8mS8y7oo","outputId":"ef81adc4-3618-4a01-91d7-deb03a814303"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîß Training Ensemble (SVM + XGBoost)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:09:05] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Ensemble Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.95      0.95      0.95       186\n","         DME       0.94      0.95      0.95       177\n","         ERM       0.95      0.94      0.94       186\n","          NO       0.97      0.97      0.97       200\n","\n","    accuracy                           0.95       749\n","   macro avg       0.95      0.95      0.95       749\n","weighted avg       0.95      0.95      0.95       749\n","\n","Accuracy: 0.9532710280373832\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QEgyiERRz9zq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from sklearn.svm import SVC\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import load_model, Model\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.inception_v3 import preprocess_input\n","from tqdm import tqdm\n","\n","# ---------- Settings ----------\n","img_size = 299\n","base_path = \"/content/drive/MyDrive/graduation project/trial_split\"\n","splits = [\"train\", \"val\", \"test\"]\n","classes = ['AMD', 'DME', 'ERM', 'NO']\n","model_path = \"/content/drive/MyDrive/graduation project/models/OCT_InceptionV3.h5\"\n","\n","# ---------- Load Model and Build Feature Extractor ----------\n","full_model = load_model(model_path)\n","feature_extractor = Model(inputs=full_model.input, outputs=full_model.layers[-3].output)  # Dropout output\n","\n","# ---------- Extract Features Function ----------\n","def extract_features(split):\n","    features, labels = [], []\n","    for class_index, class_name in enumerate(classes):\n","        class_dir = os.path.join(base_path, split, class_name)\n","        for img_file in tqdm(os.listdir(class_dir), desc=f\"{split}/{class_name}\"):\n","            img_path = os.path.join(class_dir, img_file)\n","            try:\n","                img = image.load_img(img_path, target_size=(img_size, img_size))\n","                img_array = image.img_to_array(img)\n","                img_array = np.expand_dims(img_array, axis=0)\n","                img_array = preprocess_input(img_array)\n","                feature = feature_extractor.predict(img_array, verbose=0)\n","                features.append(feature.flatten())\n","                labels.append(class_index)\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Error with {img_path}: {e}\")\n","    return np.array(features), np.array(labels)\n","\n","# ---------- Extract All Features ----------\n","print(\"üîç Extracting train features...\")\n","X_train, y_train = extract_features(\"train\")\n","print(\"üîç Extracting val features...\")\n","X_val, y_val = extract_features(\"val\")\n","print(\"üîç Extracting test features...\")\n","X_test, y_test = extract_features(\"test\")\n","\n","# ---------- Merge Train + Val ----------\n","X_combined = np.concatenate([X_train, X_val], axis=0)\n","y_combined = np.concatenate([y_train, y_val], axis=0)\n","\n","# ---------- Normalize Features ----------\n","scaler = StandardScaler()\n","X_combined = scaler.fit_transform(X_combined)\n","X_test = scaler.transform(X_test)\n","\n","# ---------- Train and Evaluate Each Model Separately ----------\n","\n","# üß† SVM\n","print(\"\\nüîß Training SVM...\")\n","svm_model = SVC(kernel='rbf', C=10, gamma='scale', probability=True)\n","svm_model.fit(X_combined, y_combined)\n","svm_preds = svm_model.predict(X_test)\n","print(\"\\nüìä SVM Results:\")\n","print(classification_report(y_test, svm_preds, target_names=classes))\n","print(f\"Accuracy: {accuracy_score(y_test, svm_preds):.4f}\")\n","\n","# üå≤ Random Forest\n","print(\"\\nüîß Training Random Forest...\")\n","rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n","rf_model.fit(X_combined, y_combined)\n","rf_preds = rf_model.predict(X_test)\n","print(\"\\nüìä Random Forest Results:\")\n","print(classification_report(y_test, rf_preds, target_names=classes))\n","print(f\"Accuracy: {accuracy_score(y_test, rf_preds):.4f}\")\n","\n","# ‚ö° XGBoost\n","print(\"\\nüîß Training XGBoost...\")\n","xgb_model = XGBClassifier(n_estimators=200, learning_rate=0.05, use_label_encoder=False, eval_metric='mlogloss')\n","xgb_model.fit(X_combined, y_combined)\n","xgb_preds = xgb_model.predict(X_test)\n","print(\"\\nüìä XGBoost Results:\")\n","print(classification_report(y_test, xgb_preds, target_names=classes))\n","print(f\"Accuracy: {accuracy_score(y_test, xgb_preds):.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDeNbWBw0Ul4","outputId":"9bfcfd56-aba6-4950-fb75-bb0bec53a3ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"]},{"output_type":"stream","name":"stdout","text":["üîç Extracting train features...\n"]},{"output_type":"stream","name":"stderr","text":["train/AMD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 861/861 [06:30<00:00,  2.21it/s]\n","train/DME: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 823/823 [05:59<00:00,  2.29it/s]\n","train/ERM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 868/868 [06:27<00:00,  2.24it/s]\n","train/NO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 929/929 [06:44<00:00,  2.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["üîç Extracting val features...\n"]},{"output_type":"stream","name":"stderr","text":["val/AMD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184/184 [01:21<00:00,  2.25it/s]\n","val/DME: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [01:15<00:00,  2.34it/s]\n","val/ERM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:21<00:00,  2.28it/s]\n","val/NO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [01:27<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["üîç Extracting test features...\n"]},{"output_type":"stream","name":"stderr","text":["test/AMD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:22<00:00,  2.27it/s]\n","test/DME: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [01:16<00:00,  2.33it/s]\n","test/ERM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:20<00:00,  2.32it/s]\n","test/NO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [01:26<00:00,  2.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîß Training SVM...\n","\n","üìä SVM Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.95      0.95      0.95       186\n","         DME       0.95      0.95      0.95       177\n","         ERM       0.95      0.92      0.94       186\n","          NO       0.96      0.97      0.97       200\n","\n","    accuracy                           0.95       749\n","   macro avg       0.95      0.95      0.95       749\n","weighted avg       0.95      0.95      0.95       749\n","\n","Accuracy: 0.9506\n","\n","üîß Training Random Forest...\n","\n","üìä Random Forest Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.95      0.96      0.95       186\n","         DME       0.95      0.95      0.95       177\n","         ERM       0.95      0.93      0.94       186\n","          NO       0.97      0.97      0.97       200\n","\n","    accuracy                           0.95       749\n","   macro avg       0.95      0.95      0.95       749\n","weighted avg       0.95      0.95      0.95       749\n","\n","Accuracy: 0.9533\n","\n","üîß Training XGBoost...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:51:40] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","üìä XGBoost Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.95      0.95      0.95       186\n","         DME       0.94      0.94      0.94       177\n","         ERM       0.94      0.93      0.94       186\n","          NO       0.96      0.97      0.97       200\n","\n","    accuracy                           0.95       749\n","   macro avg       0.95      0.95      0.95       749\n","weighted avg       0.95      0.95      0.95       749\n","\n","Accuracy: 0.9493\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from tqdm import tqdm\n","\n","# -------- Settings --------\n","img_size = 224\n","base_path = \"/content/drive/MyDrive/graduation project/trial_split\"\n","splits = [\"train\", \"val\", \"test\"]\n","classes = ['AMD', 'DME', 'ERM', 'NO']\n","model_weights_path = \"/content/drive/MyDrive/graduation project/models/squeezNet.pth\"\n","\n","# -------- Dataset Loader --------\n","class OCTDataset(Dataset):\n","    def __init__(self, image_paths, labels, transform=None):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img = Image.open(self.image_paths[idx]).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, self.labels[idx]\n","\n","# -------- Load Images --------\n","def load_images_and_labels(split):\n","    images, labels = [], []\n","    for label_index, class_name in enumerate(classes):\n","        class_path = os.path.join(base_path, split, class_name)\n","        for img_file in os.listdir(class_path):\n","            images.append(os.path.join(class_path, img_file))\n","            labels.append(label_index)\n","    return images, labels\n","\n","# -------- Transform --------\n","transform = transforms.Compose([\n","    transforms.Resize((img_size, img_size)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","\n","\n","# -------- Prepare Data --------\n","train_imgs, train_labels = load_images_and_labels(\"train\")\n","val_imgs, val_labels = load_images_and_labels(\"val\")\n","test_imgs, test_labels = load_images_and_labels(\"test\")\n","\n","X_train = extract_features(train_imgs)\n","X_val = extract_features(val_imgs)\n","X_test = extract_features(test_imgs)\n","y_train = np.array(train_labels)\n","y_val = np.array(val_labels)\n","y_test = np.array(test_labels)\n","\n","# -------- Train & Evaluate ML Models --------\n","def evaluate_model(model, X_train, y_train, X_test, y_test, name):\n","    print(f\"\\nüîß Training {name}...\")\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_test)\n","    acc = accuracy_score(y_test, preds)\n","    print(f\"\\nüìä {name} Results:\")\n","    print(classification_report(y_test, preds, target_names=classes))\n","    print(f\"Accuracy: {acc:.4f}\")\n","\n","# -------- SVM --------\n","svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True)\n","evaluate_model(svm, X_train, y_train, X_test, y_test, \"SVM\")\n","\n","# -------- Random Forest --------\n","rf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n","evaluate_model(rf, X_train, y_train, X_test, y_test, \"Random Forest\")\n","\n","# -------- XGBoost --------\n","xgb = XGBClassifier(n_estimators=200, learning_rate=0.1, use_label_encoder=False, eval_metric='mlogloss')\n","evaluate_model(xgb, X_train, y_train, X_test, y_test, \"XGBoost\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CK0DfYOiCfVj","outputId":"53edeb29-b0cb-4944-f799-091ca853cd81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3481/3481 [04:52<00:00, 11.91it/s]\n","Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [00:54<00:00, 13.67it/s]\n","Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 749/749 [00:56<00:00, 13.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîß Training SVM...\n","\n","üìä SVM Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.95      0.95      0.95       186\n","         DME       0.95      0.94      0.95       177\n","         ERM       0.96      0.96      0.96       186\n","          NO       0.96      0.98      0.97       200\n","\n","    accuracy                           0.96       749\n","   macro avg       0.96      0.96      0.96       749\n","weighted avg       0.96      0.96      0.96       749\n","\n","Accuracy: 0.9573\n","\n","üîß Training Random Forest...\n","\n","üìä Random Forest Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.91      0.98      0.95       186\n","         DME       0.97      0.93      0.95       177\n","         ERM       0.95      0.96      0.95       186\n","          NO       0.98      0.94      0.96       200\n","\n","    accuracy                           0.95       749\n","   macro avg       0.95      0.95      0.95       749\n","weighted avg       0.95      0.95      0.95       749\n","\n","Accuracy: 0.9519\n","\n","üîß Training XGBoost...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:00:34] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]}]},{"cell_type":"code","source":["!pip install scikit-learn xgboost\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29-a7lnbQoYl","outputId":"6c2afa97-fc01-4417-9956-8bcee06ae331"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from tensorflow.keras.models import load_model, Model\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tqdm import tqdm\n","\n","# --------- Settings ---------\n","img_size = 224\n","base_path = \"/content/drive/MyDrive/graduation project/trial_split\"\n","splits = [\"train\", \"val\", \"test\"]\n","classes = ['AMD', 'DME', 'ERM', 'NO']\n","model_path = \"/content/drive/MyDrive/graduation project/models/model0.h5\"\n","output_path = \"/content/drive/MyDrive/graduation project/features_vgg16\"\n","\n","os.makedirs(output_path, exist_ok=True)\n","\n","# --------- Load Your VGG16 Model and Remove Last Layer ---------\n","full_model = load_model(model_path)\n","feature_extractor = Model(inputs=full_model.input, outputs=full_model.layers[-3].output)  # Use the Flatten layer\n","\n","# --------- Function to Extract Features ---------\n","def extract_features(split):\n","    features = []\n","    labels = []\n","\n","    for class_index, class_name in enumerate(classes):\n","        class_path = os.path.join(base_path, split, class_name)\n","        image_files = os.listdir(class_path)\n","\n","        for img_file in tqdm(image_files, desc=f\"{split}/{class_name}\"):\n","            img_path = os.path.join(class_path, img_file)\n","            try:\n","                img = image.load_img(img_path, target_size=(img_size, img_size))\n","                img_array = image.img_to_array(img)\n","                img_array = np.expand_dims(img_array, axis=0)\n","                img_array = preprocess_input(img_array)\n","\n","                feature = feature_extractor.predict(img_array, verbose=0)\n","                features.append(feature.flatten())\n","                labels.append(class_index)\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Error with image {img_path}: {e}\")\n","\n","    return np.array(features), np.array(labels)\n","\n","# --------- Extract & Save ---------\n","for split in splits:\n","    print(f\"\\nüîç Extracting features for {split}...\")\n","    X, y = extract_features(split)\n","    np.save(os.path.join(output_path, f\"X_{split}.npy\"), X)\n","    np.save(os.path.join(output_path, f\"y_{split}.npy\"), y)\n","    print(f\"‚úÖ Done: {split} ‚Üí Features: {X.shape}, Labels: {y.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6jpwS0MQvjl","outputId":"1810c6cb-1463-4d61-977c-16c5c8d40994"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç Extracting features for train...\n"]},{"output_type":"stream","name":"stderr","text":["train/AMD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 861/861 [11:31<00:00,  1.25it/s]\n","train/DME: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 823/823 [11:04<00:00,  1.24it/s]\n","train/ERM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 868/868 [11:42<00:00,  1.24it/s]\n","train/NO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 929/929 [12:27<00:00,  1.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Done: train ‚Üí Features: (3481, 512), Labels: (3481,)\n","\n","üîç Extracting features for val...\n"]},{"output_type":"stream","name":"stderr","text":["val/AMD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184/184 [02:29<00:00,  1.23it/s]\n","val/DME: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [02:22<00:00,  1.23it/s]\n","val/ERM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [02:28<00:00,  1.25it/s]\n","val/NO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [02:41<00:00,  1.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Done: val ‚Üí Features: (745, 512), Labels: (745,)\n","\n","üîç Extracting features for test...\n"]},{"output_type":"stream","name":"stderr","text":["test/AMD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [02:32<00:00,  1.22it/s]\n","test/DME: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [02:29<00:00,  1.18it/s]\n","test/ERM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [02:29<00:00,  1.24it/s]\n","test/NO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [02:42<00:00,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Done: test ‚Üí Features: (749, 512), Labels: (749,)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Load features\n","X_train = np.load(output_path + \"/X_train.npy\")\n","y_train = np.load(output_path + \"/y_train.npy\")\n","X_val = np.load(output_path + \"/X_val.npy\")\n","y_val = np.load(output_path + \"/y_val.npy\")\n","X_test = np.load(output_path + \"/X_test.npy\")\n","y_test = np.load(output_path + \"/y_test.npy\")\n","\n","# Combine train + val\n","X_train_full = np.concatenate([X_train, X_val], axis=0)\n","y_train_full = np.concatenate([y_train, y_val], axis=0)\n"],"metadata":{"id":"rWZlXFYJQz71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nüîß Training SVM...\")\n","svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True)\n","svm.fit(X_train_full, y_train_full)\n","y_pred = svm.predict(X_test)\n","print(\"\\nüìä SVM Results:\")\n","print(classification_report(y_test, y_pred, target_names=classes))\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAENDWHDQ35u","outputId":"38f49d5f-ff2b-44bc-f036-7b16e1619cdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîß Training SVM...\n","\n","üìä SVM Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.93      0.89      0.91       186\n","         DME       0.89      0.90      0.90       177\n","         ERM       0.89      0.89      0.89       186\n","          NO       0.91      0.94      0.92       200\n","\n","    accuracy                           0.90       749\n","   macro avg       0.90      0.90      0.90       749\n","weighted avg       0.90      0.90      0.90       749\n","\n","Accuracy: 0.9038718291054739\n"]}]},{"cell_type":"code","source":["print(\"\\nüîß Training Random Forest...\")\n","rf = RandomForestClassifier(n_estimators=200, random_state=42)\n","rf.fit(X_train_full, y_train_full)\n","y_pred = rf.predict(X_test)\n","print(\"\\nüìä Random Forest Results:\")\n","print(classification_report(y_test, y_pred, target_names=classes))\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EeW4X58MQ-hU","outputId":"cd0bc984-e539-45b0-c46a-2dc9ce4d9c76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîß Training Random Forest...\n","\n","üìä Random Forest Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.92      0.89      0.90       186\n","         DME       0.84      0.81      0.82       177\n","         ERM       0.80      0.80      0.80       186\n","          NO       0.82      0.87      0.84       200\n","\n","    accuracy                           0.84       749\n","   macro avg       0.84      0.84      0.84       749\n","weighted avg       0.84      0.84      0.84       749\n","\n","Accuracy: 0.8411214953271028\n"]}]},{"cell_type":"code","source":["print(\"\\nüîß Training XGBoost...\")\n","xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n","xgb.fit(X_train_full, y_train_full)\n","y_pred = xgb.predict(X_test)\n","print(\"\\nüìä XGBoost Results:\")\n","print(classification_report(y_test, y_pred, target_names=classes))\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AWx12C-RCcU","outputId":"ba73fa74-d383-4b35-b98d-c4f173884f8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîß Training XGBoost...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:44:50] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","üìä XGBoost Results:\n","              precision    recall  f1-score   support\n","\n","         AMD       0.94      0.90      0.92       186\n","         DME       0.90      0.88      0.89       177\n","         ERM       0.87      0.84      0.86       186\n","          NO       0.84      0.92      0.88       200\n","\n","    accuracy                           0.89       749\n","   macro avg       0.89      0.89      0.89       749\n","weighted avg       0.89      0.89      0.89       749\n","\n","Accuracy: 0.8865153538050734\n"]}]}]}